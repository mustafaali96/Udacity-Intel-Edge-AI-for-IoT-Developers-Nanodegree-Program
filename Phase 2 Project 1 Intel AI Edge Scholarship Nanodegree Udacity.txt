Project 1: People Counting 

#Activate Env
> source /opt/intel/openvino/bin/setupvars.sh -pyver 3.5

Install NPM, from the main directory:
For MQTT/Mosca server:
> cd webservice/server
> npm install

For Web server:
> cd ../ui
> npm install

#Download Model
> wget http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz

#Extract model
> tar -xvf faster_rcnn_inception_v2_coco_2018_01_28.tar.gz

#Convert into IR
> python /opt/intel/openvino/deployment_tools/model_optimizer/mo.py --input_model faster_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb --tensorflow_object_detection_api_pipeline_config faster_rcnn_inception_v2_coco_2018_01_28/pipeline.config --reverse_input_channels --tensorflow_use_custom_operations_config /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/faster_rcnn_support.json

Step 1 - Start the Mosca server

> cd webservice/server/node-server
> node ./server.js

Step 2 - Start the GUI
Open new terminal and run below commands.

> cd webservice/ui
> npm run dev

Step 3 - FFmpeg Server
Open new terminal and run the below commands.

> sudo ffserver -f ./ffmpeg/server.conf

Step 4 - Run the code
Open a new terminal to run the code.
Setup the environment
You must configure the environment to use the Intel® Distribution of OpenVINO™ toolkit one time per session by running the following command:

> source /opt/intel/openvino/bin/setupvars.sh -pyver 3.5
> python main.py -i resources/Pedestrian_Detect_2_1_1.mp4 -m frozen_inference_graph.xml -l /opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_sse4.so -d CPU -pt 0.4 | ffmpeg -v warning -f rawvideo -pixel_format bgr24 -video_size 768x432 -framerate 24 -i - http://0.0.0.0:3004/fac.ffm
